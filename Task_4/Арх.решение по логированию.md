## Архитектурное решение по логированию
### 1. Анализ
    Проанализируйте систему компании и C4-диаграмму в контексте планирования логирования. 
    Опишите, какие логи нужно собирать, и отметьте на схеме, из каких систем требуется сбор логов. 
    Составьте список необходимых логов с уровнем INFO.

Логи с уровнем INFO на проде должны сигнализировать о ключевых моментах работы бизнес логики, например:
- инициация заказа;
- загрузка файла в 3D хранилище;
- отправка нового статуса заказа в очередь/чтение из очереди;
- сохранение изменений по заказу в хранилища (MES_DB, SHOP_DB);
- завершения стадий расчета цены в MES_API (загрузка файла, анализ модели и т.п.);
- прием HTTP запросов MES_API, SHOP_API, CRM_API;

### 2. Мотивация
    Напишите здесь, почему в систему нужно добавить логирование и что это даст компании. 
    Опишите три-пять технические и бизнес-метрики решения, на которые может повлиять внедрение логирования.
Из описания системы можно предположить, что логов сейчас недостаточно (в то, что их вообще нет, невозможно поверить), либо в них трудно разобраться (например, связать с вызовами, с заказами). 
Одновременно, мониторингов и трассировок либо нет вообще, либо почти нет.

Будем исходить из того, что:
- правильно настроенное логирование позволит собирать полноценные данные о поведении системы;
- анализ логов позволит фиксировать и искать причины ошибок и проблем;
- логирование совместно с мониторингом и трейсингом позволит улучшить `observability` системы в целом.

**Влияние на технические и бизнес-решения**

Хорошо настроенное логирование позволит:
- упростить анализ аварийных ситуаций (алерт + связщанные метрики и логи, либо трассировка + связанные логи);
- ускорить реакцию на аварии, снизив финансовые и репутационные потерь;
- автоматизировать анализ и бизнес-процессы:
  - строить верхнеуровневые метрики, например, общей забагованности;
  - создавать тикеты;
- ускорять релизы: понимать, как именно прошел запуск, устранены ли баги и т.п.;

### 3. Предлагаемое решение
    Опишите, как и с помощью каких технологий будет реализовано логирование, какие компоненты нужно внедрить или доработать. 
    Отразите компоненты и новые связи на схеме.
        
    Проработайте политику безопасности в отношении логов — как будет происходить работа с чувствительными данными, 
    кто будет иметь доступ к логам.
    
    Проработайте политику хранения в отношении логов — будет ли это отдельный индекс под систему, сколько они 
    будут храниться и какого размера будут.
#### Общие решения
1. Предлагается использовать стек `OpenSearch` для хранения общих логов и логов аудита. Но при этом для аудита применять более строгие требования.
   - OpenSearch(OS) agents в контейнерах приложений (MES_API, SHOP_API, CRM_API), а также в Messages queue и хранилищах Postgres (MES_DB, SHOP_DB) собирают, парсят, сэмплируют логи из файлов логов, которые пишут приложения (и, например, nginx) и отправляют их в Logstash.
   - Logstash парсит и обогащает и отправляет в хранилище.
   - кластер OpenSearch в качестве хранилища логов;
   - OpenSearch с помощью плагина алертинга позволяет настраивать алерты и отправку нотификации во внешние системы (смс, звонки, мессенджеры).
   - OS Dashboards + OS Dashboards UI - настройка и просмотр логов, алертов.
2. Связывание логов и трассировок по `span_id, trace_id, order_id, cart_id, user_id`.
3. Хранение логов:
   - предусмотреть ротацию логов из OS в ClickHouse;
   - ретеншн в OS: аудит 180 дней, info/debug 14 дней, error 30 дней;
   - ретеншн в ClickHouse: аудит 3 года, info/debug 3 месяца, error 6 месяцев;
   - ретеншн на инстансах: файлы до 1 недели, архивирование предыдущих дней;
4. Алерты должны логироваться в отдельный index alerts-*.
5. Объемы оценить сложно, очень грубо можно предположить, что прирост в день - до 5 GB;

![jewerly_c4_model_task4.svg](jewerly_c4_model_task4.svg)

#### Решения по безопасности
1. Использование общей инфраструктуры, но разделение пайплайнов записи и обработки обычных операционных (app, nginx и т.п.) и логов аудита (авторизация, изменения RBAC и критичных данных, фин-транзакции, экспорты данных):
   - запись логов аудита в отдельные файлы с отдельной настройкой доступа;
   - отдельные датастримы в Logstash и индексы (а может быть и ноды) в хранилище OpenSearch;
   - отдельные настройки ретеншена для операционных и аудит логов;
2. Аутентификация и RBAC для доступа к файлам, хранилищу, дашбордам, настройкам, алертов.
3. Шифрование TLS при обмене данными внутри стека OS + Logstash.
4. Токенизация в приложениях и другие способы обеспечения безопасности данных в операционных логах и логах аудита:
   - например, общие обертки для записи логов;
   - линтеры, тесты на отсутствие секретов в логах;
5. Потенциально: заведение Vault, KMS для ключей и токенов.
6. Включение аудита в самом OpenSearch.
7. Бэкапы OS.

### 4. Мероприятия для превращения системы сбора логов в систему анализа логов
    Проработайте необходимые мероприятия для превращения системы сбора логов в систему анализа логов:
    Нужно ли настроить какой-то алертинг?
    Нужно ли искать аномалии? Например, было четыре записи о создании заказов и за секунду их стало 10 000. 
    Возможно, происходит DDoS-атака конкурентами

#### Централизация, нормализация, интеграция observability-компонентов
Цель: чтобы логи были сопоставимы и пригодны для аналитики.
- единый JSON формат логов (общие поля), либо парсинг файлов в единый формат;
- централизация: сбор логов в общее хранилище;
- связывание логов с трассировками через trace_id, span_id и т.п.;
- интеграция OpenSearch и Prometheus, например;
  - в алерте ссылка на логи;
  - использование графиков из одной системы в другой;
- интеграция OpenSearch и Grafana:
  - комбинированное отображения метрик, логов и алертов;
  - использование единого инструмента для создания алертов, например, Grafana;
- интеграция OpenSearch и ClickHouse:
  - архивация старых логов в ClickHouse;
  - глубокая OLAP аналитика в ClickHouse по логам, совместно с метриками и трассировками;

#### Реактивный уровень: алертинг
Цель: чтобы система сигнализировала о проблемах без ручного поиска. Ниже примеры:
- `технический алертинг`: ошибки уровня ERROR > N в минуту по сервису -> встроенные alert rules в OpenSearch Dashboards или через Prometheus + Alertmanager;
- `бизнес алертинг`: кол-во заказов резко упало или выросло -> cоздаются агрегирующие запросы в OpenSearch и триггеры в alerting плагине;
- `security алертинг`: много запросов с одного IP -> cрабатывание правил по шаблонам (OS alerting plugin);
Важно: алерты должны идти в Telegram/Email и логироваться в отдельный index alerts-*.

#### Проактивный уровень: поиск аномалий и аналитика
Цели: обнаруживать неочевидные проблемы и атаки (DDoS, массовые ошибки, сбои). Создание управленческих бизнес-дашбордов из логов (вместе с трассировками и метриками).
- поиск сценариев DDos, например рост размера логов без роста заказов;
- OLAP аналитика в ClickHouse + ML модели для анализа логов, трассировок, метрик;
- бизнес и технические дашборды, например, общая Стабильность сервисов, потоков RPS, потоков заказов;
- security-дашборд: плохие IP, география атак;

### 5. Выбор технологий
    Проработайте критерии для выбора технологии для работы с логами и обоснуйте свой выбор через плюсы и минусы. 
    Выделите не менее пяти критериев.
Стек OpenSearch + Logstash. Ниже сравнение с ELK:

**Плюсы**
1. Полностью open-source (Apache 2.0) — можно использовать, изменять и распространять без ограничений.
2. Лицензия позволяет использовать Logstash возможно вместе с OS.
3. Активное коммьюнити (AWS + сообщества) — открытая разработка.
4. Встроенные alerting, anomaly detection и security-плагины — доступны бесплатно.
5. Оптимизация под AWS-инфраструктуру — легко интегрируется с S3.

**Минусы**
1. Отставание от Elastic по новым фичам — часть современных возможностей Elastic недоступна.
2. Иногда хуже UI и UX (OpenSearch Dashboards) — Kibana всё ещё визуально и UX-wise чуть сильнее.
3. Нестабильная совместимость плагинов Elastic — не все плагины подходят.

